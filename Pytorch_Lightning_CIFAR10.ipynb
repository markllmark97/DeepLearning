{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hBDLwEGJ03W_"
   },
   "source": [
    "## Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "FplHOfK2094n"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "lightning 2022.9.30 requires tensorboard>=2.9.1, but you have tensorboard 2.2.0 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -qqq wandb\n",
    "!pip install -qqq pytorch-lightning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bq5l7LvQ1MI6"
   },
   "source": [
    "## Import required modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "M9AO80L80smw"
   },
   "outputs": [],
   "source": [
    "# Weights & Biases\n",
    "import wandb\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "\n",
    "import pytorch_lightning.metrics\n",
    "import pytorch_lightning.callbacks as pt_callbacks\n",
    "# Pytorch modules\n",
    "import torch\n",
    "from torch.nn import functional as F\n",
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torchvision\n",
    "# Pytorch-Lightning\n",
    "from pytorch_lightning import LightningDataModule, LightningModule, Trainer\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "# Dataset\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torchvision import transforms\n",
    "from torchmetrics.functional import accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H4Y0pZwX2AsG"
   },
   "source": [
    "## Defining a model\n",
    "\n",
    "In Pytorch-Lightning, models are built with `LightningModule`, equivalent to `torch.nn.Module` but with added functionality to simplify training.\n",
    "\n",
    "Models are defined with:\n",
    "* `__init__` for model parameters\n",
    "* `forward` for inference\n",
    "* `training_step` returns a loss from a single batch\n",
    "* `configure_optimizers` defines the training optimizer\n",
    "\n",
    "Additional methods can be defined such as:\n",
    "* `validation_step` and `test_step` for logging metrics when working with validation & test data sets\n",
    "* methods such as `training_step_end` and `training_epoch_end` for more complex loops\n",
    "* other custom hooks for more flexibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = torchvision.models.resnet18(pretrained=False, num_classes=10)\n",
    "    model.conv1 = nn.Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "    model.maxpool = nn.Identity()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "WXtU8qhm1oAr"
   },
   "outputs": [],
   "source": [
    "class LitResnet(LightningModule):\n",
    "    def __init__(self, lr=0.05):\n",
    "        super().__init__()\n",
    "        self.model = create_model()\n",
    "        self.lr = lr\n",
    "        self.accuracy = pl.metrics.Accuracy()\n",
    "        self.save_hyperparameters()\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, channels, width, height = x.size()\n",
    "        out = self.model(x)\n",
    "        return F.log_softmax(out, dim=1)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = F.nll_loss(logits, y)\n",
    "        self.log(\"train_loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def evaluate(self, batch, stage=None):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = F.nll_loss(logits, y)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        acc = accuracy(preds, y)\n",
    "\n",
    "        if stage:\n",
    "            self.log(f\"{stage}_loss\", loss, prog_bar=True)\n",
    "            self.log(f\"{stage}_acc\", acc, prog_bar=True)\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        self.evaluate(batch, \"val\")\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        self.evaluate(batch, \"test\")\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        '''defines model optimizer'''\n",
    "        return Adam(self.parameters(), lr=self.lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tlkGoSEzx9f-"
   },
   "source": [
    "*Note: in this particular model we could refactor `training_step`, `validation_step` and `test_step` which share similar code.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WuRDSoBf59es"
   },
   "source": [
    "## Loading data\n",
    "\n",
    "Data pipelines can be created with:\n",
    "* Pytorch `DataLoaders`\n",
    "* LightningModule `DataLoaders`\n",
    "* `DataModules`\n",
    "\n",
    "Using `DataModules` is recommended whenever possible as its structured definition allows for additional automated optimization such as workload distribution between CPU & GPU.\n",
    "\n",
    "`DataModules` are defined with:\n",
    "* `prepare_data` (optional) which is called only once and on 1 GPU\n",
    "* `setup` which is called on each GPU separately and accepts `stage` to define if we are at `fit` or `test` step\n",
    "* `train_dataloader`, `val_dataloader` and `test_dataloader` to load respectively training, validation and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "n6EvnEfK65ML"
   },
   "outputs": [],
   "source": [
    "class CIFAR10DataModule(LightningDataModule):\n",
    "\n",
    "    def __init__(self, data_dir='./', batch_size=256):\n",
    "        super().__init__()\n",
    "        self.data_dir = data_dir\n",
    "        self.batch_size = batch_size\n",
    "        self.transform = transforms.ToTensor()\n",
    "\n",
    "    def prepare_data(self):\n",
    "        '''called only once and on 1 GPU'''\n",
    "        # download data\n",
    "        CIFAR10(self.data_dir, train=True, download=True)\n",
    "        CIFAR10(self.data_dir, train=False, download=True)\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        '''called on each GPU separately - stage defines if we are at fit or test step'''\n",
    "        # we set up only relevant datasets when stage is specified (automatically set by Pytorch-Lightning)\n",
    "        if stage == 'fit' or stage is None:\n",
    "            cifar_train = CIFAR10(self.data_dir, train=True, transform=self.transform)\n",
    "            self.cifar_train, self.cifar_val = random_split(cifar_train, [45000, 5000])\n",
    "        if stage == 'test' or stage is None:\n",
    "            self.cifar_test = CIFAR10(self.data_dir, train=False, transform=self.transform)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        '''returns training dataloader'''\n",
    "        cifar_train = DataLoader(self.cifar_train, batch_size=self.batch_size)\n",
    "        return cifar_train\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        '''returns validation dataloader'''\n",
    "        cifar_val = DataLoader(self.cifar_val, batch_size=self.batch_size)\n",
    "        return cifar_val\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        '''returns test dataloader'''\n",
    "        cifar_test = DataLoader(self.cifar_test, batch_size=self.batch_size)\n",
    "        return cifar_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o9iizemM2tXv"
   },
   "source": [
    "## Setting up Weights & Biases\n",
    "\n",
    "We log in to W&B (required only once per machine):\n",
    "* in bash, `wandb login`\n",
    "* in notebooks, `wandb.login`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "Y6fuJ6hq2ige"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmarkllmark\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3ByO-oy5JGgD"
   },
   "source": [
    "Logging to W&B is automated by `WandbLogger`. Refer to [the documentation](https://docs.wandb.com/library/integrations/lightning) for custom options.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "NI1Bh8CGI-FG"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>./wandb/run-20220930_181551-pty576s3</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/markllmark/2022320001_%EA%B9%80%EB%B3%91%EC%A4%80_pytoch%20lightning%20Cifar10/runs/pty576s3\" target=\"_blank\">neat-pine-1</a></strong> to <a href=\"https://wandb.ai/markllmark/2022320001_%EA%B9%80%EB%B3%91%EC%A4%80_pytoch%20lightning%20Cifar10\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb_logger = WandbLogger(project='2022320001_김병준_pytoch lightning Cifar10')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WC3njDPgKRd9"
   },
   "source": [
    "## Training the model\n",
    "\n",
    "We set up our data and model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "E7zB4ObdI8u8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mark/anaconda3/envs/deeplearning/lib/python3.7/site-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and will be removed in 0.15, \"\n",
      "/home/mark/anaconda3/envs/deeplearning/lib/python3.7/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# setup data\n",
    "cifar10 = CIFAR10DataModule()\n",
    " \n",
    "# setup model - choose different hyperparameters per experiment\n",
    "model = LitResnet(lr=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting https://github.com/PyTorchLightning/pytorch-lightning/archive/master.zip\n",
      "  Using cached https://github.com/PyTorchLightning/pytorch-lightning/archive/master.zip\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: croniter<1.4.0,>=1.3.0 in /home/mark/anaconda3/envs/deeplearning/lib/python3.7/site-packages (from lightning==2022.9.30) (1.3.7)\n",
      "Requirement already satisfied: packaging in /home/mark/anaconda3/envs/deeplearning/lib/python3.7/site-packages (from lightning==2022.9.30) (21.3)\n",
      "Collecting tensorboard>=2.9.1\n",
      "  Using cached tensorboard-2.10.1-py3-none-any.whl (5.9 MB)\n",
      "Requirement already satisfied: torch>=1.9.* in /home/mark/anaconda3/envs/deeplearning/lib/python3.7/site-packages (from lightning==2022.9.30) (1.12.1)\n",
      "Requirement already satisfied: fsspec[http]!=2021.06.0,>=2021.05.0 in /home/mark/anaconda3/envs/deeplearning/lib/python3.7/site-packages (from lightning==2022.9.30) (2022.8.2)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /home/mark/anaconda3/envs/deeplearning/lib/python3.7/site-packages (from lightning==2022.9.30) (4.3.0)\n",
      "Requirement already satisfied: lightning-utilities==0.3.* in /home/mark/anaconda3/envs/deeplearning/lib/python3.7/site-packages (from lightning==2022.9.30) (0.3.0)\n",
      "Requirement already satisfied: torchmetrics>=0.7.0 in /home/mark/anaconda3/envs/deeplearning/lib/python3.7/site-packages (from lightning==2022.9.30) (0.9.3)\n",
      "Requirement already satisfied: s3fs>=2022.5.0 in /home/mark/anaconda3/envs/deeplearning/lib/python3.7/site-packages (from lightning==2022.9.30) (2022.8.2)\n",
      "Requirement already satisfied: PyYAML>=5.4 in /home/mark/anaconda3/envs/deeplearning/lib/python3.7/site-packages (from lightning==2022.9.30) (6.0)\n",
      "Requirement already satisfied: lightning-cloud==0.5.7 in /home/mark/anaconda3/envs/deeplearning/lib/python3.7/site-packages (from lightning==2022.9.30) (0.5.7)\n",
      "Requirement already satisfied: numpy>=1.17.2 in /home/mark/anaconda3/envs/deeplearning/lib/python3.7/site-packages (from lightning==2022.9.30) (1.21.6)\n",
      "Requirement already satisfied: deepdiff>=5.7.0 in /home/mark/anaconda3/envs/deeplearning/lib/python3.7/site-packages (from lightning==2022.9.30) (5.8.1)\n",
      "Requirement already satisfied: tqdm>=4.57.0 in /home/mark/anaconda3/envs/deeplearning/lib/python3.7/site-packages (from lightning==2022.9.30) (4.64.1)\n",
      "Requirement already satisfied: arrow>=1.2.0 in /home/mark/anaconda3/envs/deeplearning/lib/python3.7/site-packages (from lightning==2022.9.30) (1.2.3)\n",
      "Requirement already satisfied: traitlets>=5.3.0 in /home/mark/anaconda3/envs/deeplearning/lib/python3.7/site-packages (from lightning==2022.9.30) (5.4.0)\n",
      "Requirement already satisfied: starsessions<2.0,>=1.2.1 in /home/mark/anaconda3/envs/deeplearning/lib/python3.7/site-packages (from lightning==2022.9.30) (1.3.0)\n",
      "Requirement already satisfied: urllib3 in /home/mark/anaconda3/envs/deeplearning/lib/python3.7/site-packages (from lightning-cloud==0.5.7->lightning==2022.9.30) (1.26.12)\n",
      "Requirement already satisfied: requests in /home/mark/anaconda3/envs/deeplearning/lib/python3.7/site-packages (from lightning-cloud==0.5.7->lightning==2022.9.30) (2.28.1)\n",
      "Requirement already satisfied: fastapi[all] in /home/mark/anaconda3/envs/deeplearning/lib/python3.7/site-packages (from lightning-cloud==0.5.7->lightning==2022.9.30) (0.85.0)\n",
      "Requirement already satisfied: click in /home/mark/anaconda3/envs/deeplearning/lib/python3.7/site-packages (from lightning-cloud==0.5.7->lightning==2022.9.30) (8.1.3)\n",
      "Requirement already satisfied: rich in /home/mark/anaconda3/envs/deeplearning/lib/python3.7/site-packages (from lightning-cloud==0.5.7->lightning==2022.9.30) (12.5.1)\n",
      "Requirement already satisfied: six in /home/mark/anaconda3/envs/deeplearning/lib/python3.7/site-packages (from lightning-cloud==0.5.7->lightning==2022.9.30) (1.16.0)\n",
      "Requirement already satisfied: websocket-client in /home/mark/anaconda3/envs/deeplearning/lib/python3.7/site-packages (from lightning-cloud==0.5.7->lightning==2022.9.30) (0.58.0)\n",
      "Requirement already satisfied: pyjwt in /home/mark/anaconda3/envs/deeplearning/lib/python3.7/site-packages (from lightning-cloud==0.5.7->lightning==2022.9.30) (2.5.0)\n",
      "Requirement already satisfied: fire in /home/mark/anaconda3/envs/deeplearning/lib/python3.7/site-packages (from lightning-utilities==0.3.*->lightning==2022.9.30) (0.4.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7.0 in /home/mark/anaconda3/envs/deeplearning/lib/python3.7/site-packages (from arrow>=1.2.0->lightning==2022.9.30) (2.8.2)\n",
      "Requirement already satisfied: ordered-set<4.2.0,>=4.1.0 in /home/mark/anaconda3/envs/deeplearning/lib/python3.7/site-packages (from deepdiff>=5.7.0->lightning==2022.9.30) (4.1.0)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /home/mark/anaconda3/envs/deeplearning/lib/python3.7/site-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->lightning==2022.9.30) (3.8.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/mark/anaconda3/envs/deeplearning/lib/python3.7/site-packages (from packaging->lightning==2022.9.30) (3.0.9)\n",
      "Requirement already satisfied: aiobotocore~=2.4.0 in /home/mark/anaconda3/envs/deeplearning/lib/python3.7/site-packages (from s3fs>=2022.5.0->lightning==2022.9.30) (2.4.0)\n",
      "Requirement already satisfied: starlette<1,>=0 in /home/mark/anaconda3/envs/deeplearning/lib/python3.7/site-packages (from starsessions<2.0,>=1.2.1->lightning==2022.9.30) (0.20.4)\n",
      "Requirement already satisfied: itsdangerous<3.0.0,>=2.0.1 in /home/mark/anaconda3/envs/deeplearning/lib/python3.7/site-packages (from starsessions<2.0,>=1.2.1->lightning==2022.9.30) (2.1.2)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/mark/anaconda3/envs/deeplearning/lib/python3.7/site-packages (from tensorboard>=2.9.1->lightning==2022.9.30) (1.8.1)\n",
      "Requirement already satisfied: absl-py>=0.4 in /home/mark/anaconda3/envs/deeplearning/lib/python3.7/site-packages (from tensorboard>=2.9.1->lightning==2022.9.30) (1.2.0)\n",
      "Requirement already satisfied: wheel>=0.26 in /home/mark/anaconda3/envs/deeplearning/lib/python3.7/site-packages (from tensorboard>=2.9.1->lightning==2022.9.30) (0.37.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /home/mark/anaconda3/envs/deeplearning/lib/python3.7/site-packages (from tensorboard>=2.9.1->lightning==2022.9.30) (0.6.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/mark/anaconda3/envs/deeplearning/lib/python3.7/site-packages (from tensorboard>=2.9.1->lightning==2022.9.30) (2.2.2)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/mark/anaconda3/envs/deeplearning/lib/python3.7/site-packages (from tensorboard>=2.9.1->lightning==2022.9.30) (0.4.6)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/mark/anaconda3/envs/deeplearning/lib/python3.7/site-packages (from tensorboard>=2.9.1->lightning==2022.9.30) (1.35.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /home/mark/anaconda3/envs/deeplearning/lib/python3.7/site-packages (from tensorboard>=2.9.1->lightning==2022.9.30) (63.4.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/mark/anaconda3/envs/deeplearning/lib/python3.7/site-packages (from tensorboard>=2.9.1->lightning==2022.9.30) (3.4.1)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in /home/mark/anaconda3/envs/deeplearning/lib/python3.7/site-packages (from tensorboard>=2.9.1->lightning==2022.9.30) (1.49.1)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /home/mark/anaconda3/envs/deeplearning/lib/python3.7/site-packages (from tensorboard>=2.9.1->lightning==2022.9.30) (3.19.6)\n",
      "Requirement already satisfied: aioitertools>=0.5.1 in /home/mark/anaconda3/envs/deeplearning/lib/python3.7/site-packages (from aiobotocore~=2.4.0->s3fs>=2022.5.0->lightning==2022.9.30) (0.11.0)\n",
      "Requirement already satisfied: botocore<1.27.60,>=1.27.59 in /home/mark/anaconda3/envs/deeplearning/lib/python3.7/site-packages (from aiobotocore~=2.4.0->s3fs>=2022.5.0->lightning==2022.9.30) (1.27.59)\n",
      "Requirement already satisfied: wrapt>=1.10.10 in /home/mark/anaconda3/envs/deeplearning/lib/python3.7/site-packages (from aiobotocore~=2.4.0->s3fs>=2022.5.0->lightning==2022.9.30) (1.14.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/mark/anaconda3/envs/deeplearning/lib/python3.7/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->lightning==2022.9.30) (22.1.0)\n",
      "Requirement already satisfied: asynctest==0.13.0 in /home/mark/anaconda3/envs/deeplearning/lib/python3.7/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->lightning==2022.9.30) (0.13.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /home/mark/anaconda3/envs/deeplearning/lib/python3.7/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->lightning==2022.9.30) (4.0.2)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /home/mark/anaconda3/envs/deeplearning/lib/python3.7/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->lightning==2022.9.30) (2.1.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/mark/anaconda3/envs/deeplearning/lib/python3.7/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->lightning==2022.9.30) (1.8.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/mark/anaconda3/envs/deeplearning/lib/python3.7/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->lightning==2022.9.30) (6.0.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/mark/anaconda3/envs/deeplearning/lib/python3.7/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->lightning==2022.9.30) (1.3.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/mark/anaconda3/envs/deeplearning/lib/python3.7/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->lightning==2022.9.30) (1.2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/mark/anaconda3/envs/deeplearning/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->lightning==2022.9.30) (4.9)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /home/mark/anaconda3/envs/deeplearning/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->lightning==2022.9.30) (4.2.4)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/mark/anaconda3/envs/deeplearning/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->lightning==2022.9.30) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/mark/anaconda3/envs/deeplearning/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.9.1->lightning==2022.9.30) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /home/mark/anaconda3/envs/deeplearning/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard>=2.9.1->lightning==2022.9.30) (4.12.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/mark/anaconda3/envs/deeplearning/lib/python3.7/site-packages (from requests->lightning-cloud==0.5.7->lightning==2022.9.30) (2022.9.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/mark/anaconda3/envs/deeplearning/lib/python3.7/site-packages (from requests->lightning-cloud==0.5.7->lightning==2022.9.30) (3.4)\n",
      "Requirement already satisfied: anyio<5,>=3.4.0 in /home/mark/anaconda3/envs/deeplearning/lib/python3.7/site-packages (from starlette<1,>=0->starsessions<2.0,>=1.2.1->lightning==2022.9.30) (3.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/mark/anaconda3/envs/deeplearning/lib/python3.7/site-packages (from werkzeug>=1.0.1->tensorboard>=2.9.1->lightning==2022.9.30) (2.1.1)\n",
      "Requirement already satisfied: pydantic!=1.7,!=1.7.1,!=1.7.2,!=1.7.3,!=1.8,!=1.8.1,<2.0.0,>=1.6.2 in /home/mark/anaconda3/envs/deeplearning/lib/python3.7/site-packages (from fastapi[all]->lightning-cloud==0.5.7->lightning==2022.9.30) (1.10.2)\n",
      "Requirement already satisfied: ujson!=4.0.2,!=4.1.0,!=4.2.0,!=4.3.0,!=5.0.0,!=5.1.0,<6.0.0,>=4.0.1 in /home/mark/anaconda3/envs/deeplearning/lib/python3.7/site-packages (from fastapi[all]->lightning-cloud==0.5.7->lightning==2022.9.30) (5.5.0)\n",
      "Requirement already satisfied: python-multipart<0.0.6,>=0.0.5 in /home/mark/anaconda3/envs/deeplearning/lib/python3.7/site-packages (from fastapi[all]->lightning-cloud==0.5.7->lightning==2022.9.30) (0.0.5)\n",
      "Requirement already satisfied: email-validator<2.0.0,>=1.1.1 in /home/mark/anaconda3/envs/deeplearning/lib/python3.7/site-packages (from fastapi[all]->lightning-cloud==0.5.7->lightning==2022.9.30) (1.3.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.2.1 in /home/mark/anaconda3/envs/deeplearning/lib/python3.7/site-packages (from fastapi[all]->lightning-cloud==0.5.7->lightning==2022.9.30) (3.8.0)\n",
      "Requirement already satisfied: uvicorn[standard]<0.19.0,>=0.12.0 in /home/mark/anaconda3/envs/deeplearning/lib/python3.7/site-packages (from fastapi[all]->lightning-cloud==0.5.7->lightning==2022.9.30) (0.18.3)\n",
      "Requirement already satisfied: jinja2<4.0.0,>=2.11.2 in /home/mark/anaconda3/envs/deeplearning/lib/python3.7/site-packages (from fastapi[all]->lightning-cloud==0.5.7->lightning==2022.9.30) (3.0.3)\n",
      "Requirement already satisfied: termcolor in /home/mark/anaconda3/envs/deeplearning/lib/python3.7/site-packages (from fire->lightning-utilities==0.3.*->lightning==2022.9.30) (2.0.1)\n",
      "Requirement already satisfied: commonmark<0.10.0,>=0.9.0 in /home/mark/anaconda3/envs/deeplearning/lib/python3.7/site-packages (from rich->lightning-cloud==0.5.7->lightning==2022.9.30) (0.9.1)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.6.0 in /home/mark/anaconda3/envs/deeplearning/lib/python3.7/site-packages (from rich->lightning-cloud==0.5.7->lightning==2022.9.30) (2.11.2)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/mark/anaconda3/envs/deeplearning/lib/python3.7/site-packages (from anyio<5,>=3.4.0->starlette<1,>=0->starsessions<2.0,>=1.2.1->lightning==2022.9.30) (1.2.0)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /home/mark/anaconda3/envs/deeplearning/lib/python3.7/site-packages (from botocore<1.27.60,>=1.27.59->aiobotocore~=2.4.0->s3fs>=2022.5.0->lightning==2022.9.30) (1.0.1)\n",
      "Requirement already satisfied: dnspython>=1.15.0 in /home/mark/anaconda3/envs/deeplearning/lib/python3.7/site-packages (from email-validator<2.0.0,>=1.1.1->fastapi[all]->lightning-cloud==0.5.7->lightning==2022.9.30) (2.2.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/mark/anaconda3/envs/deeplearning/lib/python3.7/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.9.1->lightning==2022.9.30) (3.8.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/mark/anaconda3/envs/deeplearning/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.9.1->lightning==2022.9.30) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/mark/anaconda3/envs/deeplearning/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.9.1->lightning==2022.9.30) (3.2.1)\n",
      "Requirement already satisfied: h11>=0.8 in /home/mark/anaconda3/envs/deeplearning/lib/python3.7/site-packages (from uvicorn[standard]<0.19.0,>=0.12.0->fastapi[all]->lightning-cloud==0.5.7->lightning==2022.9.30) (0.14.0)\n",
      "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /home/mark/anaconda3/envs/deeplearning/lib/python3.7/site-packages (from uvicorn[standard]<0.19.0,>=0.12.0->fastapi[all]->lightning-cloud==0.5.7->lightning==2022.9.30) (0.17.0)\n",
      "Requirement already satisfied: websockets>=10.0 in /home/mark/anaconda3/envs/deeplearning/lib/python3.7/site-packages (from uvicorn[standard]<0.19.0,>=0.12.0->fastapi[all]->lightning-cloud==0.5.7->lightning==2022.9.30) (10.3)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in /home/mark/anaconda3/envs/deeplearning/lib/python3.7/site-packages (from uvicorn[standard]<0.19.0,>=0.12.0->fastapi[all]->lightning-cloud==0.5.7->lightning==2022.9.30) (0.21.0)\n",
      "Requirement already satisfied: httptools>=0.4.0 in /home/mark/anaconda3/envs/deeplearning/lib/python3.7/site-packages (from uvicorn[standard]<0.19.0,>=0.12.0->fastapi[all]->lightning-cloud==0.5.7->lightning==2022.9.30) (0.5.0)\n",
      "Requirement already satisfied: watchfiles>=0.13 in /home/mark/anaconda3/envs/deeplearning/lib/python3.7/site-packages (from uvicorn[standard]<0.19.0,>=0.12.0->fastapi[all]->lightning-cloud==0.5.7->lightning==2022.9.30) (0.17.0)\n",
      "Installing collected packages: tensorboard\n",
      "  Attempting uninstall: tensorboard\n",
      "    Found existing installation: tensorboard 2.2.0\n",
      "    Uninstalling tensorboard-2.2.0:\n",
      "      Successfully uninstalled tensorboard-2.2.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "pytorch-lightning 0.9.0 requires tensorboard==2.2.0, but you have tensorboard 2.10.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed tensorboard-2.10.1\n"
     ]
    }
   ],
   "source": [
    "!pip install https://github.com/PyTorchLightning/pytorch-lightning/archive/master.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yfT7TkTsVwan"
   },
   "source": [
    "We can then set up our trainer and customize several options, such as gradient accumulation, half precision training and distributed computing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "CxXtBfFrKYgA"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mark/anaconda3/envs/deeplearning/lib/python3.7/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:446: LightningDeprecationWarning: Setting `Trainer(gpus=-1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=-1)` instead.\n",
      "  f\"Setting `Trainer(gpus={gpus!r})` is deprecated in v1.7 and will be removed\"\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    logger=wandb_logger,    # W&B integration\n",
    "    gpus=-1,                # use all GPU's\n",
    "    max_epochs=20            # number of epochs\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lk75Ex0cWEIT"
   },
   "source": [
    "Training just requires a call to `fit` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "9xSW1nrBWGem"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./cifar-10-python.tar.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65ecf424169e4036b178f37f29d77826",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/170498071 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./cifar-10-python.tar.gz to ./\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name     | Type     | Params\n",
      "--------------------------------------\n",
      "0 | model    | ResNet   | 11.2 M\n",
      "1 | accuracy | Accuracy | 0     \n",
      "--------------------------------------\n",
      "11.2 M    Trainable params\n",
      "0         Non-trainable params\n",
      "11.2 M    Total params\n",
      "44.696    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mark/anaconda3/envs/deeplearning/lib/python3.7/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:235: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 20 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n",
      "/home/mark/anaconda3/envs/deeplearning/lib/python3.7/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:235: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 20 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c10a4fa7ad8248d097ff07f36a6d22d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=20` reached.\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model, cifar10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MYtIwe-DWMBg"
   },
   "source": [
    "When a test set is available, we just need to call the `test` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "T6dD01TpWP8G"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/home/mark/anaconda3/envs/deeplearning/lib/python3.7/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:235: PossibleUserWarning: The dataloader, test_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 20 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1a7f821c1d1487398655e3809d54cd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_acc          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.711899995803833     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    1.8210960626602173     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_acc         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.711899995803833    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   1.8210960626602173    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 1.8210960626602173, 'test_acc': 0.711899995803833}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.test(model, datamodule=cifar10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LvhwTDtNX0z3"
   },
   "source": [
    "When we want to close our W&B run, we can call `wandb.finish()` (mainly useful in notebooks, called automatically in scripts)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "DbxIU2ZoXzcQ"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▇▇▇▇▇▇████</td></tr><tr><td>test_acc</td><td>▁</td></tr><tr><td>test_loss</td><td>▁</td></tr><tr><td>train_loss</td><td>██▇▆▅▅▅▅▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>val_acc</td><td>▁▄▄▅▅▇▇▇▇█▇█▇███▇███</td></tr><tr><td>val_loss</td><td>█▄▄▂▂▁▁▂▃▁▂▂▃▂▂▄▅▃▃▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>20</td></tr><tr><td>test_acc</td><td>0.7119</td></tr><tr><td>test_loss</td><td>1.8211</td></tr><tr><td>train_loss</td><td>0.06786</td></tr><tr><td>trainer/global_step</td><td>3520</td></tr><tr><td>val_acc</td><td>0.721</td></tr><tr><td>val_loss</td><td>1.81783</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">neat-pine-1</strong>: <a href=\"https://wandb.ai/markllmark/2022320001_%EA%B9%80%EB%B3%91%EC%A4%80_pytoch%20lightning%20Cifar10/runs/pty576s3\" target=\"_blank\">https://wandb.ai/markllmark/2022320001_%EA%B9%80%EB%B3%91%EC%A4%80_pytoch%20lightning%20Cifar10/runs/pty576s3</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220930_181551-pty576s3/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
